<style>
/* Styles modernes pour le cours KNN */
.course-header {
    background: linear-gradient(135deg, rgba(102, 126, 234, 0.1), rgba(118, 75, 162, 0.05));
    backdrop-filter: blur(20px);
    border-radius: 24px;
    padding: 3rem;
    margin: 2rem 0;
    border: 1px solid rgba(102, 126, 234, 0.2);
    text-align: center;
}

.course-title {
    font-size: 3rem;
    font-weight: 700;
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    background-clip: text;
    margin-bottom: 1rem;
}

.course-subtitle {
    color: #7f8c8d;
    font-size: 1.2rem;
    font-weight: 300;
    margin-bottom: 2rem;
}

.timeline-section {
    background: var(--md-default-bg-color);
    border-radius: 20px;
    padding: 2rem;
    margin: 2rem 0;
    box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
    border: 1px solid rgba(255, 255, 255, 0.2);
}

.section-title {
    font-size: 2.2rem;
    font-weight: 600;
    color: #667eea;
    margin-bottom: 2rem;
    text-align: center;
}

.definition-box {
    background: linear-gradient(135deg, rgba(102, 126, 234, 0.1), rgba(118, 75, 162, 0.05));
    border-left: 5px solid #667eea;
    border-radius: 12px;
    padding: 2rem;
    margin: 2rem 0;
    backdrop-filter: blur(10px);
}

.definition-title {
    font-size: 1.3rem;
    font-weight: 600;
    color: #667eea;
    margin-bottom: 1rem;
}

.definition-content {
    color: var(--md-default-fg-color);
    font-size: 1.1rem;
    line-height: 1.6;
}

.highlight-fact {
    background: rgba(255, 193, 7, 0.1);
    border-left: 4px solid #ffc107;
    padding: 1rem;
    margin: 1rem 0;
    border-radius: 8px;
    font-weight: 500;
}

.fact-content {
    color: var(--md-default-fg-color);
    font-weight: 500;
    line-height: 1.6;
}

.info-box {
    background: linear-gradient(135deg, rgba(102, 126, 234, 0.1), rgba(118, 75, 162, 0.05));
    border-left: 5px solid #667eea;
    border-radius: 12px;
    padding: 2rem;
    margin: 2rem 0;
    backdrop-filter: blur(10px);
}

.info-title {
    font-size: 1.3rem;
    font-weight: 600;
    color: #667eea;
    margin-bottom: 1rem;
}

.info-content {
    color: var(--md-default-fg-color);
    font-size: 1.1rem;
    line-height: 1.6;
}

.code-example {
    background: #1a202c;
    color: #e2e8f0;
    padding: 1.5rem;
    border-radius: 10px;
    margin: 1.5rem 0;
    font-family: 'Courier New', monospace;
    overflow-x: auto;
    border-left: 4px solid #4299e1;
}

.code-title {
    color: #4299e1;
    font-weight: 700;
    margin-bottom: 1rem;
    font-size: 1rem;
}

.steps-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
    gap: 1rem;
    margin: 1rem 0;
}

.step-card {
    background: rgba(255, 255, 255, 0.6);
    border-radius: 15px;
    padding: 1.5rem;
    border: 1px solid rgba(255, 255, 255, 0.4);
    transition: all 0.3s ease;
    position: relative;
    overflow: hidden;
    backdrop-filter: blur(5px);
}

.step-card:hover {
    transform: translateY(-5px);
    box-shadow: 0 12px 24px rgba(0, 0, 0, 0.1);
}

/* Styles pour les avantages et inconv√©nients */
.advantages-disadvantages {
    display: grid;
    grid-template-columns: 1fr 1fr;
    gap: 20px;
    margin: 20px 0;
}

.advantage-card, .disadvantage-card {
    background: white;
    border-radius: 12px;
    padding: 20px;
    box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
    transition: all 0.3s ease;
}

.advantage-card {
    border-left: 4px solid #10b981;
}

.disadvantage-card {
    border-left: 4px solid #ef4444;
}

.advantage-card:hover, .disadvantage-card:hover {
    transform: translateY(-2px);
    box-shadow: 0 6px 20px rgba(0, 0, 0, 0.15);
}

.advantage-card .card-title {
    font-size: 1.1em;
    font-weight: bold;
    color: #10b981;
    margin-bottom: 15px;
    display: flex;
    align-items: center;
    gap: 8px;
}

.disadvantage-card .card-title {
    font-size: 1.1em;
    font-weight: bold;
    color: #ef4444;
    margin-bottom: 15px;
    display: flex;
    align-items: center;
    gap: 8px;
}

.card-content {
    color: #374151;
    line-height: 1.6;
}

.card-content ul {
    margin: 0;
    padding-left: 20px;
}

.card-content li {
    margin-bottom: 8px;
}

@media (max-width: 768px) {
    .advantages-disadvantages {
        grid-template-columns: 1fr;
    }
}

.step-number {
    background: #667eea;
    color: white;
    width: 2rem;
    height: 2rem;
    border-radius: 50%;
    display: flex;
    align-items: center;
    justify-content: center;
    font-weight: 600;
    margin-bottom: 1rem;
}

.step-title {
    font-weight: 600;
    margin-bottom: 1rem;
    font-size: 1.2rem;
    color: #2c3e50;
}

.step-description {
    font-size: 0.9rem;
    color: #7f8c8d;
    line-height: 1.6;
}

.advantages-disadvantages {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
    gap: 2rem;
    margin: 2rem 0;
}

.advantage-card, .disadvantage-card {
    background: rgba(255, 255, 255, 0.6);
    border-radius: 15px;
    padding: 2rem;
    border: 1px solid rgba(255, 255, 255, 0.4);
    transition: all 0.3s ease;
    backdrop-filter: blur(5px);
}

.advantage-card {
    border-left: 5px solid #27ae60;
}

.disadvantage-card {
    border-left: 5px solid #e74c3c;
}

.advantage-card:hover, .disadvantage-card:hover {
    transform: translateY(-5px);
    box-shadow: 0 12px 24px rgba(0, 0, 0, 0.1);
}

.card-title {
    font-weight: 600;
    margin-bottom: 1rem;
    font-size: 1.3rem;
    color: #2c3e50;
}

.card-content {
    font-size: 0.95rem;
    color: #7f8c8d;
    line-height: 1.6;
}

.card-content ul {
    margin: 0.5rem 0;
    padding-left: 1rem;
}
</style>

<div class="course-header">
    <h1 class="course-title">üìö Algorithme des K Plus Proches Voisins</h1>
    <p class="course-subtitle">Comprendre l'algorithme KNN et ses applications</p>
</div>

<div class="timeline-section">
    <h2 class="section-title">üìñ D√©finition</h2>
    
    <div class="definition-box">
        <div class="definition-title">ü§ñ Qu'est-ce que l'algorithme KNN ?</div>
        <div class="definition-content">
            L'algorithme des K Plus Proches Voisins (K-Nearest Neighbors ou KNN) est une m√©thode d'<strong>apprentissage supervis√©</strong> simple et intuitive, utilis√©e principalement pour des probl√®mes de <strong>classification</strong> et de <strong>r√©gression</strong>.
        </div>
    </div>
    
    <div class="info-box">
        <div class="info-title">üîç Concepts cl√©s</div>
        <div class="info-content">
            <ul>
                <li><strong>Apprentissage supervis√©</strong> : L'algorithme apprend √† partir d'un ensemble de donn√©es o√π les "bonnes r√©ponses" (√©tiquettes ou valeurs) sont d√©j√† connues.</li>
                <li><strong>Classification</strong> : Pr√©dire √† quelle cat√©gorie appartient un nouvel √©l√©ment (par exemple, si un email est un spam ou non).</li>
                <li><strong>R√©gression</strong> : Pr√©dire une valeur continue pour un nouvel √©l√©ment (par exemple, estimer le prix d'une maison).</li>
            </ul>
        </div>
    </div>
    
    <div class="highlight-fact">
        <div class="fact-content">
            <strong>üí° Principe fondamental :</strong> L'id√©e centrale de KNN est que des choses similaires existent √† proximit√© les unes des autres. Un nouvel √©l√©ment sera probablement similaire √† ses voisins les plus proches dans l'ensemble de donn√©es d'entra√Ænement.
        </div>
    </div>
</div>

<div class="timeline-section">
    <h2 class="section-title">‚öôÔ∏è Comment fonctionne KNN ?</h2>
    
    <div class="steps-grid">
        <div class="step-card">
            <div class="step-number">1</div>
            <div class="step-title">Choisir le nombre K</div>
            <div class="step-description">
                On d√©finit K, le nombre de voisins les plus proches √† consid√©rer. C'est un param√®tre important √† r√©gler.
            </div>
        </div>
        
        <div class="step-card">
            <div class="step-number">2</div>
            <div class="step-title">Calculer les distances</div>
            <div class="step-description">
                Pour un nouvel √©l√©ment, on calcule la distance entre cet √©l√©ment et tous les autres √©l√©ments de l'ensemble de donn√©es d'entra√Ænement. La mesure de distance la plus courante est la <strong>distance euclidienne</strong>.
            </div>
        </div>
        
        <div class="step-card">
            <div class="step-number">3</div>
            <div class="step-title">Identifier les K voisins</div>
            <div class="step-description">
                On s√©lectionne les K √©l√©ments de l'ensemble d'entra√Ænement qui sont les plus proches du nouvel √©l√©ment (ceux ayant les plus petites distances).
            </div>
        </div>
        
        <div class="step-card">
            <div class="step-number">4</div>
            <div class="step-title">Prendre une d√©cision</div>
            <div class="step-description">
                <strong>Classification :</strong> On regarde la cat√©gorie majoritaire parmi les K voisins.<br>
                <strong>R√©gression :</strong> On calcule la moyenne des valeurs des K voisins.
            </div>
        </div>
    </div>
    
    <div class="info-box">
        <div class="info-title">üìù Exemple simple de classification</div>
        <div class="info-content">
            Imaginons que nous ayons des points de donn√©es de deux cat√©gories (A et B) et un nouveau point inconnu (X). Si nous choisissons K=3 :
            <ol>
                <li>On calcule la distance entre X et tous les autres points.</li>
                <li>On trouve les 3 points les plus proches de X.</li>
                <li>Si 2 de ces 3 voisins sont de la cat√©gorie A et 1 est de la cat√©gorie B, alors X sera classifi√© comme A.</li>
            </ol>
        </div>
    </div>
</div>

<div class="timeline-section">
    <h2 class="section-title">üìè La mesure de distance</h2>
    
    <div class="definition-box">
        <div class="definition-title">üìê Distance euclidienne</div>
        <div class="definition-content">
            La <strong>distance euclidienne</strong> est la plus utilis√©e. Pour deux points P(p1, p2, ..., pn) et Q(q1, q2, ..., qn) dans un espace √† n dimensions, la distance euclidienne est :
        </div>
    </div>
    
    <div class="code-example">
        <div class="code-title">üìä Formule de la distance euclidienne</div>
        <pre>
d(P, Q) = ‚àö((p1-q1)¬≤ + (p2-q2)¬≤ + ... + (pn-qn)¬≤)
        </pre>
    </div>
    
    <div class="info-box">
        <div class="info-title">üìè Autres mesures de distance</div>
        <div class="info-content">
            D'autres mesures de distance existent, comme la distance de Manhattan ou la distance de Minkowski.
        </div>
    </div>
    
    <div class="highlight-fact">
        <div class="fact-content">
            <strong>‚ö†Ô∏è Important - Normalisation des donn√©es :</strong> Si les diff√©rentes caract√©ristiques (dimensions) de vos donn√©es n'ont pas la m√™me √©chelle (par exemple, une caract√©ristique varie de 0 √† 1 et une autre de 0 √† 1000), celles avec des valeurs plus grandes domineront le calcul de la distance. Il est donc crucial de <strong>normaliser</strong> ou <strong>standardiser</strong> vos donn√©es avant d'appliquer KNN.
        </div>
    </div>
</div>

<div class="timeline-section">
    <h2 class="section-title">üéØ Choisir la valeur de K</h2>
    
    <div class="definition-box">
        <div class="definition-title">‚öñÔ∏è L'importance du choix de K</div>
        <div class="definition-content">
            Le choix de K est crucial pour la performance de l'algorithme. Il faut trouver un √©quilibre entre sensibilit√© et robustesse.
        </div>
    </div>
    
    <div class="steps-grid">
        <div class="step-card">
            <div class="step-title">üìâ K petit (ex: K=1)</div>
            <div class="step-description">
                L'algorithme est tr√®s sensible au bruit et aux points aberrants. Le mod√®le peut √™tre trop sp√©cifique aux donn√©es d'entra√Ænement (surapprentissage ou overfitting).
            </div>
        </div>
        
        <div class="step-card">
            <div class="step-title">üìà K grand</div>
            <div class="step-description">
                L'algorithme est plus robuste au bruit, mais peut rendre les fronti√®res de d√©cision moins distinctes. Si K est trop grand, tous les nouveaux points seront classifi√©s dans la cat√©gorie majoritaire.
            </div>
        </div>
    </div>
    
    <div class="info-box">
        <div class="info-title">üí° Conseils pour choisir K</div>
        <div class="info-content">
            <ul>
                <li>Il n'y a pas de r√®gle d'or pour choisir K</li>
                <li>On utilise souvent des techniques comme la <strong>validation crois√©e</strong> pour trouver une valeur optimale</li>
                <li>Une pratique courante est de choisir K comme un <strong>nombre impair</strong> pour √©viter les √©galit√©s en classification binaire</li>
            </ul>
        </div>
    </div>
</div>

<div class="timeline-section">
    <h2 class="section-title">‚öñÔ∏è Avantages et Inconv√©nients</h2>
    
    <div class="advantages-disadvantages">
        <div class="advantage-card">
            <div class="card-title">‚úÖ Avantages de KNN</div>
            <div class="card-content">
                <ul>
                    <li><strong>Simple √† comprendre et √† impl√©menter</strong></li>
                    <li><strong>Non param√©trique</strong> : Il ne fait aucune supposition sur la distribution sous-jacente des donn√©es</li>
                    <li><strong>Polyvalent</strong> : Peut √™tre utilis√© pour la classification et la r√©gression</li>
                    <li><strong>S'adapte facilement</strong> : De nouvelles donn√©es peuvent √™tre ajout√©es sans avoir √† r√©-entra√Æner le mod√®le (apprentissage "paresseux" ou "lazy learning")</li>
                </ul>
            </div>
        </div>
        
        <div class="disadvantage-card">
            <div class="card-title">‚ùå Inconv√©nients de KNN</div>
            <div class="card-content">
                <ul>
                    <li><strong>Co√ªteux en calcul</strong> : Pour chaque nouvelle pr√©diction, il faut calculer la distance √† tous les points de l'ensemble d'entra√Ænement</li>
                    <li><strong>Sensible aux dimensions non pertinentes</strong> ("fl√©au de la dimensionnalit√©")</li>
                    <li><strong>N√©cessite une normalisation des donn√©es</strong> : Les √©chelles des caract√©ristiques influencent fortement les distances</li>
                    <li><strong>N√©cessite beaucoup de m√©moire</strong> : Il faut stocker tout l'ensemble de donn√©es d'entra√Ænement</li>
                    <li><strong>Le choix de K est critique</strong></li>
                </ul>
            </div>
        </div>
    </div>
</div>

<div class="timeline-section">
    <h2 class="section-title">üéØ Quand utiliser KNN ?</h2>
    
    <div class="info-box">
        <div class="info-title">üìã Cas d'usage recommand√©s</div>
        <div class="info-content">
            KNN peut √™tre un bon point de d√©part pour des probl√®mes de classification ou de r√©gression, surtout si :
            <ul>
                <li>L'ensemble de donn√©es n'est pas excessivement grand</li>
                <li>Les relations entre les caract√©ristiques et la cible sont complexes et non lin√©aires</li>
                <li>Vous avez besoin d'une m√©thode simple et interpr√©table</li>
            </ul>
        </div>
    </div>
    
    <div class="highlight-fact">
        <div class="fact-content">
            <strong>üí° Utilisation pratique :</strong> KNN est souvent utilis√© comme baseline pour comparer avec des mod√®les plus complexes.
        </div>
    </div>
</div>

</body>
</html>