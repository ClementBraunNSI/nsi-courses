# Fiche d'exercices : K plus proches voisins (k-NN)

<style>
/* Styles pour les fiches d'exercices avec syst√®me de cartes et onglets */

.exercise-cards {
    display: flex;
    flex-direction: column;
    gap: 1rem;
    padding: 1rem 0;
    max-width: 100%;
}

.exercise-card {
    background: var(--md-default-bg-color);
    border-radius: 8px;
    padding: 1rem;
    box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
    transition: transform 0.3s ease, box-shadow 0.3s ease;
    border-left: 3px solid;
    width: 100%;
    max-width: 100%;
    min-height: fit-content;
}

.exercise-card:hover {
    transform: translateY(-2px);
    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.15);
}

.exercise-card.intro {
    border-left-color: #4CAF50;
}

.exercise-card.medium {
    border-left-color: #FF9800;
}

.exercise-card.hard {
    border-left-color: #F44336;
}

.difficulty-badge {
    display: inline-block;
    padding: 0.25rem 0.75rem;
    border-radius: 12px;
    font-size: 0.8rem;
    font-weight: bold;
    margin-bottom: 0.5rem;
}

.difficulty-badge.intro {
    background-color: rgba(76, 175, 80, 0.1);
    color: #4CAF50;
}

.difficulty-badge.medium {
    background-color: rgba(255, 152, 0, 0.1);
    color: #FF9800;
}

.difficulty-badge.hard {
    background-color: rgba(244, 67, 54, 0.1);
    color: #F44336;
}

.exercise-title {
    font-size: 1.1rem;
    font-weight: bold;
    margin-bottom: 0.5rem;
    color: var(--md-default-fg-color);
}

.exercise-content {
    color: var(--md-default-fg-color--light);
    line-height: 1.5;
    margin-bottom: 1rem;
}

.toggle-solution {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    border: none;
    padding: 0.5rem 1rem;
    border-radius: 6px;
    cursor: pointer;
    font-size: 0.9rem;
    transition: all 0.3s ease;
    display: flex;
    align-items: center;
    gap: 0.5rem;
}

.toggle-solution:hover {
    transform: translateY(-1px);
    box-shadow: 0 4px 12px rgba(102, 126, 234, 0.3);
}

.arrow {
    transition: transform 0.3s ease;
}

.solution-wrapper {
    max-height: 0;
    overflow: hidden;
    transition: max-height 0.4s ease;
}

.solution-wrapper.show {
    max-height: 2000px;
    margin-top: 1rem;
}

.solution {
    background: rgba(102, 126, 234, 0.05);
    border-radius: 8px;
    padding: 1rem;
    border-left: 3px solid #667eea;
}

.solution pre {
    background: rgba(0, 0, 0, 0.05);
    padding: 1rem;
    border-radius: 6px;
    overflow-x: auto;
    margin: 0;
}

.solution code {
    font-family: 'Courier New', monospace;
    font-size: 0.9rem;
}

.data-table {
    border-collapse: collapse;
    width: 100%;
    margin: 1rem 0;
}

.data-table th, .data-table td {
    border: 1px solid #ddd;
    padding: 8px;
    text-align: center;
}

.data-table th {
    background-color: #f2f2f2;
    font-weight: bold;
}

.highlight-row {
    background-color: #fff3cd;
}
</style>

## üìö Partie 1 : Concepts fondamentaux du k-NN

<div class="exercise-cards">
    <div class="exercise-card intro">
        <div class="difficulty-badge intro">Introduction ü¶ä</div>
        <h4 class="exercise-title">Exercice 1 - Principe de base</h4>
        <div class="exercise-content">
            <strong>Expliquez le principe de l'algorithme k-NN :</strong><br><br>
            1. Que signifie "k-NN" ?<br>
            2. Comment fonctionne la classification avec k-NN ?<br>
            3. Quelle est la diff√©rence entre k=1 et k=5 ?<br>
            4. Pourquoi utilise-t-on g√©n√©ralement un k impair ?<br>
            5. Quels sont les avantages et inconv√©nients de k-NN ?
        </div>
        <button class="toggle-solution" onclick="toggleSolution(this)">
            <span class="arrow">‚Üí</span> Voir la correction
        </button>
        <div class="solution-wrapper">
            <div class="solution">
                <strong>Explications :</strong><br>
                1. <strong>k-NN :</strong> k-Nearest Neighbors (k plus proches voisins)<br><br>
                2. <strong>Fonctionnement :</strong><br>
                   ‚Ä¢ Calculer la distance entre le point √† classifier et tous les points d'entra√Ænement<br>
                   ‚Ä¢ S√©lectionner les k points les plus proches<br>
                   ‚Ä¢ Attribuer la classe majoritaire parmi ces k voisins<br><br>
                3. <strong>Diff√©rence k=1 vs k=5 :</strong><br>
                   ‚Ä¢ k=1 : Classification bas√©e sur le voisin le plus proche uniquement<br>
                   ‚Ä¢ k=5 : Classification bas√©e sur le vote des 5 voisins les plus proches<br><br>
                4. <strong>k impair :</strong> √âvite les √©galit√©s lors du vote (pas d'ex-aequo)<br><br>
                5. <strong>Avantages :</strong> Simple, pas d'hypoth√®se sur les donn√©es, efficace pour donn√©es non-lin√©aires<br>
                   <strong>Inconv√©nients :</strong> Co√ªteux en calcul, sensible aux donn√©es aberrantes, n√©cessite beaucoup de m√©moire
            </div>
        </div>
    </div>

    <div class="exercise-card intro">
        <div class="difficulty-badge intro">Introduction ü¶ä</div>
        <h4 class="exercise-title">Exercice 2 - Calcul de distance</h4>
        <div class="exercise-content">
            <strong>Calculez la distance euclidienne entre ces points :</strong><br><br>
            Point A : (2, 3)<br>
            Point B : (5, 7)<br>
            Point C : (1, 1)<br><br>
            <strong>Questions :</strong><br>
            1. Distance entre A et B<br>
            2. Distance entre A et C<br>
            3. Distance entre B et C<br>
            4. Quel point est le plus proche de A ?
        </div>
        <button class="toggle-solution" onclick="toggleSolution(this)">
            <span class="arrow">‚Üí</span> Voir la correction
        </button>
        <div class="solution-wrapper">
            <div class="solution">
                <strong>Calculs (formule : ‚àö[(x‚ÇÇ-x‚ÇÅ)¬≤ + (y‚ÇÇ-y‚ÇÅ)¬≤]) :</strong><br><br>
                1. <strong>Distance A-B :</strong><br>
                   ‚àö[(5-2)¬≤ + (7-3)¬≤] = ‚àö[3¬≤ + 4¬≤] = ‚àö[9 + 16] = ‚àö25 = 5<br><br>
                2. <strong>Distance A-C :</strong><br>
                   ‚àö[(1-2)¬≤ + (1-3)¬≤] = ‚àö[(-1)¬≤ + (-2)¬≤] = ‚àö[1 + 4] = ‚àö5 ‚âà 2.24<br><br>
                3. <strong>Distance B-C :</strong><br>
                   ‚àö[(1-5)¬≤ + (1-7)¬≤] = ‚àö[(-4)¬≤ + (-6)¬≤] = ‚àö[16 + 36] = ‚àö52 ‚âà 7.21<br><br>
                4. <strong>Plus proche de A :</strong> Point C (distance ‚âà 2.24)
            </div>
        </div>
    </div>

    <div class="exercise-card medium">
        <div class="difficulty-badge medium">Moyen ü¶äü¶ä</div>
        <h4 class="exercise-title">Exercice 3 - Classification simple</h4>
        <div class="exercise-content">
            <strong>Donn√©es d'entra√Ænement (Taille, Poids, Classe) :</strong><br><br>
            <table class="data-table">
                <tr><th>Point</th><th>Taille (cm)</th><th>Poids (kg)</th><th>Classe</th></tr>
                <tr><td>1</td><td>160</td><td>50</td><td>A</td></tr>
                <tr><td>2</td><td>170</td><td>65</td><td>B</td></tr>
                <tr><td>3</td><td>155</td><td>45</td><td>A</td></tr>
                <tr><td>4</td><td>180</td><td>80</td><td>B</td></tr>
                <tr><td>5</td><td>165</td><td>55</td><td>A</td></tr>
            </table><br>
            <strong>Nouveau point √† classifier :</strong> (162, 52)<br>
            Utilisez k=3 pour classifier ce point.
        </div>
        <button class="toggle-solution" onclick="toggleSolution(this)">
            <span class="arrow">‚Üí</span> Voir la correction
        </button>
        <div class="solution-wrapper">
            <div class="solution">
                <strong>Calcul des distances :</strong><br><br>
                Point √† classifier : (162, 52)<br><br>
                <table class="data-table">
                    <tr><th>Point</th><th>Distance</th><th>Classe</th></tr>
                    <tr class="highlight-row"><td>1</td><td>‚àö[(162-160)¬≤ + (52-50)¬≤] = ‚àö8 ‚âà 2.83</td><td>A</td></tr>
                    <tr><td>2</td><td>‚àö[(162-170)¬≤ + (52-65)¬≤] = ‚àö233 ‚âà 15.26</td><td>B</td></tr>
                    <tr class="highlight-row"><td>3</td><td>‚àö[(162-155)¬≤ + (52-45)¬≤] = ‚àö98 ‚âà 9.90</td><td>A</td></tr>
                    <tr><td>4</td><td>‚àö[(162-180)¬≤ + (52-80)¬≤] = ‚àö1108 ‚âà 33.29</td><td>B</td></tr>
                    <tr class="highlight-row"><td>5</td><td>‚àö[(162-165)¬≤ + (52-55)¬≤] = ‚àö18 ‚âà 4.24</td><td>A</td></tr>
                </table><br>
                <strong>3 plus proches voisins :</strong> Points 1, 5, 3<br>
                <strong>Classes :</strong> A, A, A<br>
                <strong>Classification :</strong> Classe A (vote unanime)
            </div>
        </div>
    </div>
</div>

## üìö Partie 2 : Impl√©mentation en Python

<div class="exercise-cards">
    <div class="exercise-card medium">
        <div class="difficulty-badge medium">Moyen ü¶äü¶ä</div>
        <h4 class="exercise-title">Exercice 4 - Fonction de distance</h4>
        <div class="exercise-content">
            <strong>Impl√©mentez une fonction qui calcule la distance euclidienne :</strong><br><br>
            <pre>
def distance_euclidienne(point1, point2):
    """
    Calcule la distance euclidienne entre deux points
    point1 et point2 sont des listes [x, y]
    """
    # √Ä compl√©ter
    pass
            </pre><br>
            <strong>Testez avec :</strong><br>
            ‚Ä¢ distance_euclidienne([0, 0], [3, 4]) ‚Üí doit retourner 5.0<br>
            ‚Ä¢ distance_euclidienne([1, 1], [4, 5]) ‚Üí doit retourner 5.0
        </div>
        <button class="toggle-solution" onclick="toggleSolution(this)">
            <span class="arrow">‚Üí</span> Voir la correction
        </button>
        <div class="solution-wrapper">
            <div class="solution">
                <strong>Impl√©mentation :</strong><br>
                <pre>
import math

def distance_euclidienne(point1, point2):
    """
    Calcule la distance euclidienne entre deux points
    point1 et point2 sont des listes [x, y]
    """
    x1, y1 = point1
    x2, y2 = point2
    return math.sqrt((x2 - x1)**2 + (y2 - y1)**2)

# Tests
print(distance_euclidienne([0, 0], [3, 4]))  # 5.0
print(distance_euclidienne([1, 1], [4, 5]))  # 5.0
                </pre>
            </div>
        </div>
    </div>

    <div class="exercise-card medium">
        <div class="difficulty-badge medium">Moyen ü¶äü¶ä</div>
        <h4 class="exercise-title">Exercice 5 - Trouver les k plus proches voisins</h4>
        <div class="exercise-content">
            <strong>Impl√©mentez une fonction qui trouve les k plus proches voisins :</strong><br><br>
            <pre>
def k_plus_proches_voisins(point_test, donnees_entrainement, k):
    """
    Trouve les k plus proches voisins d'un point
    point_test : [x, y]
    donnees_entrainement : liste de [x, y, classe]
    k : nombre de voisins √† retourner
    """
    # √Ä compl√©ter
    pass
            </pre>
        </div>
        <button class="toggle-solution" onclick="toggleSolution(this)">
            <span class="arrow">‚Üí</span> Voir la correction
        </button>
        <div class="solution-wrapper">
            <div class="solution">
                <strong>Impl√©mentation :</strong><br>
                <pre>
def k_plus_proches_voisins(point_test, donnees_entrainement, k):
    """
    Trouve les k plus proches voisins d'un point
    point_test : [x, y]
    donnees_entrainement : liste de [x, y, classe]
    k : nombre de voisins √† retourner
    """
    distances = []
    
    # Calculer la distance pour chaque point d'entra√Ænement
    for donnee in donnees_entrainement:
        point_entrainement = [donnee[0], donnee[1]]
        classe = donnee[2]
        dist = distance_euclidienne(point_test, point_entrainement)
        distances.append((dist, classe, donnee))
    
    # Trier par distance croissante
    distances.sort(key=lambda x: x[0])
    
    # Retourner les k premiers
    return distances[:k]

# Exemple d'utilisation
donnees = [[160, 50, 'A'], [170, 65, 'B'], [155, 45, 'A']]
voisins = k_plus_proches_voisins([162, 52], donnees, 2)
print(voisins)
                </pre>
            </div>
        </div>
    </div>

    <div class="exercise-card hard">
        <div class="difficulty-badge hard">Difficile ü¶äü¶äü¶ä</div>
        <h4 class="exercise-title">Exercice 6 - Algorithme k-NN complet</h4>
        <div class="exercise-content">
            <strong>Impl√©mentez l'algorithme k-NN complet :</strong><br><br>
            <pre>
def classifier_knn(point_test, donnees_entrainement, k):
    """
    Classifie un point avec l'algorithme k-NN
    Retourne la classe pr√©dite
    """
    # √Ä compl√©ter
    pass

def evaluer_knn(donnees_test, donnees_entrainement, k):
    """
    √âvalue la pr√©cision de l'algorithme k-NN
    Retourne le pourcentage de bonnes classifications
    """
    # √Ä compl√©ter
    pass
            </pre>
        </div>
        <button class="toggle-solution" onclick="toggleSolution(this)">
            <span class="arrow">‚Üí</span> Voir la correction
        </button>
        <div class="solution-wrapper">
            <div class="solution">
                <strong>Impl√©mentation compl√®te :</strong><br>
                <pre>
def classifier_knn(point_test, donnees_entrainement, k):
    """
    Classifie un point avec l'algorithme k-NN
    Retourne la classe pr√©dite
    """
    # Trouver les k plus proches voisins
    voisins = k_plus_proches_voisins(point_test, donnees_entrainement, k)
    
    # Compter les votes pour chaque classe
    votes = {}
    for distance, classe, donnee in voisins:
        if classe in votes:
            votes[classe] += 1
        else:
            votes[classe] = 1
    
    # Retourner la classe avec le plus de votes
    classe_predite = max(votes, key=votes.get)
    return classe_predite

def evaluer_knn(donnees_test, donnees_entrainement, k):
    """
    √âvalue la pr√©cision de l'algorithme k-NN
    Retourne le pourcentage de bonnes classifications
    """
    bonnes_predictions = 0
    total_predictions = len(donnees_test)
    
    for donnee_test in donnees_test:
        point_test = [donnee_test[0], donnee_test[1]]
        vraie_classe = donnee_test[2]
        
        classe_predite = classifier_knn(point_test, donnees_entrainement, k)
        
        if classe_predite == vraie_classe:
            bonnes_predictions += 1
    
    precision = (bonnes_predictions / total_predictions) * 100
    return precision

# Exemple d'utilisation
entrainement = [[160, 50, 'A'], [170, 65, 'B'], [155, 45, 'A'], 
                [180, 80, 'B'], [165, 55, 'A']]
test = [[162, 52, 'A'], [175, 70, 'B']]

print(f"Pr√©cision avec k=3: {evaluer_knn(test, entrainement, 3):.1f}%")
                </pre>
            </div>
        </div>
    </div>
</div>

## üìö Partie 3 : Applications pratiques

<div class="exercise-cards">
    <div class="exercise-card medium">
        <div class="difficulty-badge medium">Moyen ü¶äü¶ä</div>
        <h4 class="exercise-title">Exercice 7 - Choix de k optimal</h4>
        <div class="exercise-content">
            <strong>Analysez l'impact de diff√©rentes valeurs de k :</strong><br><br>
            Donn√©es : 100 points d'entra√Ænement, 2 classes √©quilibr√©es<br><br>
            <table class="data-table">
                <tr><th>k</th><th>Pr√©cision (%)</th><th>Temps (ms)</th></tr>
                <tr><td>1</td><td>85</td><td>10</td></tr>
                <tr><td>3</td><td>92</td><td>12</td></tr>
                <tr><td>5</td><td>94</td><td>15</td></tr>
                <tr><td>10</td><td>91</td><td>25</td></tr>
                <tr><td>20</td><td>88</td><td>45</td></tr>
                <tr><td>50</td><td>82</td><td>95</td></tr>
            </table><br>
            <strong>Questions :</strong><br>
            1. Quelle valeur de k choisiriez-vous ?<br>
            2. Pourquoi k=1 donne-t-il une pr√©cision plus faible ?<br>
            3. Pourquoi k=50 donne-t-il une pr√©cision plus faible ?
        </div>
        <button class="toggle-solution" onclick="toggleSolution(this)">
            <span class="arrow">‚Üí</span> Voir la correction
        </button>
        <div class="solution-wrapper">
            <div class="solution">
                <strong>Analyse :</strong><br><br>
                1. <strong>Choix optimal :</strong> k=5 (meilleure pr√©cision 94% avec temps raisonnable)<br><br>
                2. <strong>Probl√®me k=1 :</strong><br>
                   ‚Ä¢ Tr√®s sensible au bruit et aux donn√©es aberrantes<br>
                   ‚Ä¢ Pas de lissage, d√©cisions trop locales<br>
                   ‚Ä¢ Overfitting possible<br><br>
                3. <strong>Probl√®me k=50 :</strong><br>
                   ‚Ä¢ k trop grand par rapport √† la taille des donn√©es (50% des donn√©es)<br>
                   ‚Ä¢ Perte de la structure locale des donn√©es<br>
                   ‚Ä¢ Tendance vers la classe majoritaire globale<br>
                   ‚Ä¢ Underfitting<br><br>
                <strong>R√®gle g√©n√©rale :</strong> k ‚âà ‚àön o√π n est le nombre de points d'entra√Ænement
            </div>
        </div>
    </div>

    <div class="exercise-card hard">
        <div class="difficulty-badge hard">Difficile ü¶äü¶äü¶ä</div>
        <h4 class="exercise-title">Exercice 8 - Syst√®me de recommandation</h4>
        <div class="exercise-content">
            <strong>Cr√©ez un syst√®me de recommandation de films avec k-NN :</strong><br><br>
            <strong>Donn√©es utilisateurs (notes sur 5) :</strong><br>
            <table class="data-table">
                <tr><th>Utilisateur</th><th>Action</th><th>Com√©die</th><th>Drame</th><th>Sci-Fi</th></tr>
                <tr><td>Alice</td><td>5</td><td>2</td><td>4</td><td>1</td></tr>
                <tr><td>Bob</td><td>1</td><td>5</td><td>2</td><td>4</td></tr>
                <tr><td>Charlie</td><td>4</td><td>3</td><td>5</td><td>2</td></tr>
                <tr><td>Diana</td><td>2</td><td>4</td><td>1</td><td>5</td></tr>
            </table><br>
            <strong>Nouvel utilisateur :</strong> Eve (Action: 4, Com√©die: 1, Drame: 5, Sci-Fi: ?)<br>
            Pr√©disez la note de Eve pour les films Sci-Fi avec k=2.
        </div>
        <button class="toggle-solution" onclick="toggleSolution(this)">
            <span class="arrow">‚Üí</span> Voir la correction
        </button>
        <div class="solution-wrapper">
            <div class="solution">
                <strong>Solution :</strong><br><br>
                <strong>1. Calcul des distances (sans Sci-Fi) :</strong><br>
                Eve : [4, 1, 5]<br><br>
                ‚Ä¢ Alice [5, 2, 4] : ‚àö[(4-5)¬≤ + (1-2)¬≤ + (5-4)¬≤] = ‚àö3 ‚âà 1.73<br>
                ‚Ä¢ Bob [1, 5, 2] : ‚àö[(4-1)¬≤ + (1-5)¬≤ + (5-2)¬≤] = ‚àö34 ‚âà 5.83<br>
                ‚Ä¢ Charlie [4, 3, 5] : ‚àö[(4-4)¬≤ + (1-3)¬≤ + (5-5)¬≤] = ‚àö4 = 2.00<br>
                ‚Ä¢ Diana [2, 4, 1] : ‚àö[(4-2)¬≤ + (1-4)¬≤ + (5-1)¬≤] = ‚àö29 ‚âà 5.39<br><br>
                <strong>2. Les 2 plus proches voisins :</strong><br>
                ‚Ä¢ Alice (distance 1.73, Sci-Fi: 1)<br>
                ‚Ä¢ Charlie (distance 2.00, Sci-Fi: 2)<br><br>
                <strong>3. Pr√©diction :</strong><br>
                Moyenne pond√©r√©e par l'inverse de la distance :<br>
                Poids Alice = 1/1.73 ‚âà 0.58<br>
                Poids Charlie = 1/2.00 = 0.50<br><br>
                Note pr√©dite = (1√ó0.58 + 2√ó0.50) / (0.58 + 0.50) ‚âà 1.46<br><br>
                <strong>Pr√©diction pour Eve en Sci-Fi : ‚âà 1.5/5</strong>
            </div>
        </div>
    </div>

    <div class="exercise-card hard">
        <div class="difficulty-badge hard">Difficile ü¶äü¶äü¶ä</div>
        <h4 class="exercise-title">Exercice 9 - Optimisations et variantes</h4>
        <div class="exercise-content">
            <strong>Analysez ces am√©liorations de l'algorithme k-NN :</strong><br><br>
            1. <strong>k-NN pond√©r√© :</strong> Les voisins plus proches ont plus d'influence<br>
            2. <strong>Normalisation :</strong> Mettre toutes les features √† la m√™me √©chelle<br>
            3. <strong>Distance de Manhattan :</strong> |x‚ÇÅ-x‚ÇÇ| + |y‚ÇÅ-y‚ÇÇ|<br>
            4. <strong>R√©duction de dimensionnalit√© :</strong> PCA avant k-NN<br><br>
            <strong>Questions :</strong><br>
            ‚Ä¢ Quand utiliser chaque am√©lioration ?<br>
            ‚Ä¢ Impl√©mentez la distance de Manhattan<br>
            ‚Ä¢ Pourquoi normaliser les donn√©es ?
        </div>
        <button class="toggle-solution" onclick="toggleSolution(this)">
            <span class="arrow">‚Üí</span> Voir la correction
        </button>
        <div class="solution-wrapper">
            <div class="solution">
                <strong>Analyse des am√©liorations :</strong><br><br>
                <strong>1. k-NN pond√©r√© :</strong><br>
                ‚Ä¢ Utilisation : Quand la proximit√© est tr√®s importante<br>
                ‚Ä¢ Poids = 1/distance ou exp(-distance)<br><br>
                <strong>2. Normalisation :</strong><br>
                ‚Ä¢ N√©cessaire quand les features ont des √©chelles diff√©rentes<br>
                ‚Ä¢ Exemple : √¢ge (0-100) vs salaire (20000-100000)<br>
                <pre>
def normaliser(donnees):
    # Min-Max normalization
    for i in range(len(donnees[0])-1):  # -1 pour exclure la classe
        valeurs = [point[i] for point in donnees]
        min_val, max_val = min(valeurs), max(valeurs)
        for point in donnees:
            point[i] = (point[i] - min_val) / (max_val - min_val)
    return donnees
                </pre><br>
                <strong>3. Distance de Manhattan :</strong><br>
                <pre>
def distance_manhattan(point1, point2):
    return sum(abs(a - b) for a, b in zip(point1, point2))
                </pre>
                ‚Ä¢ Utilisation : Donn√©es avec features ind√©pendantes, moins sensible aux outliers<br><br>
                <strong>4. R√©duction de dimensionnalit√© :</strong><br>
                ‚Ä¢ Utilisation : Donn√©es haute dimension, r√©duction du bruit
                ‚Ä¢ Am√©liore les performances et r√©duit la mal√©diction de la dimensionnalit√©
            </div>
        </div>
    </div>
</div>

<script>
// JavaScript pour les fonctionnalit√©s interactives des fiches d'exercices
function toggleSolution(button) {
    const wrapper = button.nextElementSibling;
    const arrow = button.querySelector('.arrow');
    
    if (wrapper.classList.contains('show')) {
        wrapper.classList.remove('show');
        arrow.textContent = '‚Üí';
        arrow.style.transform = 'rotate(0deg)';
    } else {
        wrapper.classList.add('show');
        arrow.textContent = '‚Üì';
        arrow.style.transform = 'rotate(90deg)';
    }
}

// Initialisation au chargement de la page
document.addEventListener('DOMContentLoaded', function() {
    // Aucune initialisation sp√©cifique n√©cessaire pour cette fiche
});
</script>